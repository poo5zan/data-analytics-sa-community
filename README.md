<!-- To preview markdown in vscode in MAC: press CMD + Shift + V  . This helps in editing markdown-->
# data-analytics-volunteer

This repository will contain the codes for data analysis for sacommunity


1. Create Python Virtual Environment. Let's name it sacommunity_data_analytics_venv
Reference: https://docs.python.org/3/library/venv.html

2. create command
python -m venv .venv


3. activate the virtual environment
source .venv/bin/activate


4. install dependencies from requirements.txt
pip install -r requirements.txt

# Google Analytics Api Retrieval
1. Copy settings/app_settings_sample.json and rename it to app_settings.json
2. Add value for ViewId_V4 property. Login to google analytics (https://analytics.google.com/). In the "Analytics Accounts" menu, the integer number below the website url is the viewId. The viewId is  For security reason, the value is not added in the github
3. Create credentials in google analytics console. 
Create a project: 
    Navigate to console: https://console.cloud.google.com/
    Click on Project drop down list.
    Click on New Project
    Give a project name. Example: SACommunity Google Analytics
    Optionally edit the project id. You can leave the default id generated by google
    
After the new project is created. From the notifications, click on Select Project
Click on APIs & Services
Click on Credentials
Click on 'Create Credentials' and Click on 'OAuth client ID'
Click on Configure Consent Screen

# Configure Consent Screen
Select User Type = External
Fill the app information
    App name : SA Community GA
    User support email
    Developer contact information

Enable APIS:
   Google Analytics Data API: https://console.cloud.google.com/apis/library/analyticsdata.googleapis.com?project=puju-ga

   Google Analytics API: https://console.cloud.google.com/apis/library/analytics.googleapis.com?project=puju-ga

   Google Analytics Reporting API: https://console.cloud.google.com/apis/library/analyticsreporting.googleapis.com?project=puju-ga


Refresh the page.

Add scopes
https://www.googleapis.com/auth/analytics.readonly

Click on Save and Continue

Add Test Users - Add your email
click save and continue

Go back to dashboard
Click on Credentials
Click on Create Credentials -> OAuth client ID
Application type = Desktop app
Name = SACommunityGADesktopClient
click save
Download JSON

# Create Service account
Fill Service account details
1. Service account name
2. Service account description
Click Create and Continue
Grant Role - Select role of Viewer. You don't want to give owner access.
Click Done

# Create Keys
Click on created service account
Click on Keys
Click on Add Key and Click on create new key
Select Key type = Json
click create

Client libraries quick start: https://developers.google.com/analytics/devguides/reporting/data/v1/quickstart-client-libraries

Enable the Google Analytics Data API v1
Enter project name : SACommunity Google Analytics
Download private key as json


Navigate to https://console.cloud.google.com/apis/credentials and skip upto 3.2
    <!-- 3.1 Click on 'API & Services'
    3.2 Click on Credentials -->
    3.3 
    3.4 Select application type = Web application
    3.5 Give it a name for the OAuth client. Eg. OAuthForSACommunityGAWebClient
    3.6 Add http://localhost in the Authorized redirect URIs
    3.6 Download the json credentials and save it as oauth_credentials.json in ./credentials folder



## Coding Convention
1. pylint
https://pylint.readthedocs.io/en/stable/

    check warnings from pylint with following command (do not supress warning from pylint unless necessary, resolve as many warnings as possible)

    pylint $(git ls-files '*.py')

2. Run unit tests

    python -m unittest discover -s ./tests/helpers -p "*_tests.py"

3. Logging (File based)
https://docs.python.org/3/library/logging.html

    Persistent logging enables to go through the error messages to debug. We are storing logs in file in logs folder

## How to run code
1. Jobs to fetch daily data (job_run.py)

## Future Plan - Roadmap (TODO)
2. Prepare report (Invoke Manually)

    i. User enters date range (say fiscal year)

    ii. System downloads 3 files data and transforms it into 5 files

    iii. Automate Power BI report

3. Implement Airflow for jobs (ETL - Extract, Transform and Load)

4. Extract - Extract data from google analytics api

    Verify that the downloads are working as expected. Compare, cross-check some samples against google analytics web portal

5. Transform - 

    Clean the data, 
    
    find missing data,
    
    resolve data issues, 
    
    prepare new data format for power BI

    prepare new data format for canva

6. Load - 

    Save the files in local disk
    (iff we get appropriate permissions to write in sharepoint, then will upload files to sharepoint)

7. Automate Power BI report

8. Automate Canva Report

9. Make GUI for all the operations

